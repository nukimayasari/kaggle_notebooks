{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9657831,"sourceType":"datasetVersion","datasetId":5900046}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nukimayasari/credit-score-gradio-deployment?scriptVersionId=204158993\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T18:20:35.463443Z","iopub.execute_input":"2024-10-29T18:20:35.464494Z","iopub.status.idle":"2024-10-29T18:20:35.49299Z","shell.execute_reply.started":"2024-10-29T18:20:35.464444Z","shell.execute_reply":"2024-10-29T18:20:35.491623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Credit Score Gradio Deployment**\n\nThis Notebook demonstrates the end-to-end process of deploying a credit score classification model using Gradio. We’ll start by understanding our dataset, performing a few initial exploratory steps, and setting up our model for deployment. By the end, you’ll see how the model is accessible to users for real-time predictions via a Gradio interface.\n\n## Step 1: Load the Dataset\nWe begin by loading the dataset containing credit score information. This dataset includes important features like the interest rate, the number of credit inquiries, outstanding debt, and other financial metrics, which will be used to predict a credit score category (Good, Standard, or Poor).","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/credit-score-classification-cleaned-dataset/credit_score_cleaned_train.csv\", index_col=0)\ndisplay(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-29T18:20:38.709646Z","iopub.execute_input":"2024-10-29T18:20:38.710561Z","iopub.status.idle":"2024-10-29T18:20:40.028588Z","shell.execute_reply.started":"2024-10-29T18:20:38.710504Z","shell.execute_reply":"2024-10-29T18:20:40.027492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This initial display of the dataset’s first few rows gives us a glimpse into the data structure, making it easy to verify that the dataset has loaded correctly.\n\n## Step 2: Explore Credit Score Categories\nTo understand the prediction target, let’s look at the unique values in the credit_score column. This will clarify the categories we aim to classify.","metadata":{}},{"cell_type":"code","source":"df.credit_score.unique()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T18:20:42.993711Z","iopub.execute_input":"2024-10-29T18:20:42.99413Z","iopub.status.idle":"2024-10-29T18:20:43.005805Z","shell.execute_reply.started":"2024-10-29T18:20:42.994089Z","shell.execute_reply":"2024-10-29T18:20:43.004511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output will reveal the categories available for prediction. For instance, the categories are represented as numeric codes like 2, 1, and 0, corresponding to \"Good,\" \"Standard,\" and \"Poor.\"\n\n## Step 3: Summary Statistics\nNext, we generate descriptive statistics to gain insights into the distribution of numerical features, which helps identify any potential outliers or feature scaling needs before training the model.","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:32:35.084735Z","iopub.execute_input":"2024-10-27T16:32:35.085966Z","iopub.status.idle":"2024-10-27T16:32:35.211536Z","shell.execute_reply.started":"2024-10-27T16:32:35.085886Z","shell.execute_reply":"2024-10-27T16:32:35.210197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This table provides an overview of key statistical measures for each feature, such as the mean, standard deviation, minimum, and maximum values, giving us a sense of the data’s overall distribution.\n\n## Step 4: Inspect Column Names\nReviewing the column names helps confirm the feature names and their format. This is crucial for ensuring that the dataset aligns with our model's expectations.\n\n## Step 5: Data Structure and Types\nFinally, examining the data structure and types provides insights into how each feature is stored, confirming whether any categorical features need encoding or if there are null values that need handling.","metadata":{}},{"cell_type":"code","source":"display(df.columns)\ndisplay(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:32:35.214738Z","iopub.execute_input":"2024-10-27T16:32:35.215316Z","iopub.status.idle":"2024-10-27T16:32:35.350605Z","shell.execute_reply.started":"2024-10-27T16:32:35.215253Z","shell.execute_reply":"2024-10-27T16:32:35.34908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Columns\n\n* customer_id: A unique identifier for each customer. It’s generally not used as a feature because it doesn’t contain predictive value for creditworthiness.\n\n* month: Likely indicates the time period for the data. It could be useful in a time-based analysis but might not contribute directly to credit scoring.\n\n* name: The customer's name.\n\n* age: The age of the customer, which can be useful for understanding credit risk. Younger individuals may have less credit history, for example.\n\n* ssn (Social Security Number): A unique identifier in the U.S., mainly for identification purposes. It’s generally excluded from analysis for privacy.\n\n* occupation: The customer’s job type, which could correlate with income stability and risk. Some occupations might imply higher or lower risk levels.\n\n* annual_income: Total income in a year. This is a strong indicator of creditworthiness since higher income might mean better repayment capacity.\n\n* monthly_inhand_salary: The income the customer has each month after deductions. Similar to annual income, this affects the customer’s ability to repay loans.\n\n* total_emi_per_month: The total amount the customer pays monthly on existing loans. A high EMI relative to income could imply a higher risk of default.\n\n* num_bank_accounts: The number of bank accounts the customer holds. While this isn’t directly tied to risk, many accounts could suggest better access to financial services.\n\n* num_credit_card: The number of credit cards held by the customer. Too many or too few could be signals for credit behavior analysis.\n\n* interest_rate: The interest rate on existing loans. Higher rates often increase the financial burden, affecting creditworthiness.\n\n* num_of_loan: The number of loans the customer has taken. High numbers of loans might indicate high risk, especially if income is low.\n\n* type_of_loan: Types of loans (e.g., personal, home, education). Different loan types have varied risk profiles.\n\n* delay_from_due_date: Average delay in days for making payments. A high delay might indicate poor repayment behavior.\n\n* num_of_delayed_payment: Total number of payments delayed. Consistent delays are usually a red flag in credit scoring.\n\n* changed_credit_limit: Change in the credit limit for credit cards or loans. A decrease in credit limit could be due to risky behavior, while an increase might indicate good standing.\n\n* num_credit_inquiries: The number of times the customer’s credit has been checked. Too many inquiries can indicate financial strain or risky behavior.\n\n* credit_mix: The diversity of credit accounts (e.g., a mix of credit cards, mortgages, personal loans). A well-balanced credit mix is often viewed positively.\n\n* outstanding_debt: The total debt the customer has. Higher outstanding debt generally indicates higher risk, especially if income is low.\n\n* credit_utilization_ratio: The ratio of used credit to available credit, a key indicator of credit health. Lower ratios usually imply better credit management.\n\n* credit_history_age: The length of the customer’s credit history. Longer histories are generally favorable since they show experience in handling credit.\n\n* payment_of_min_amount: Whether the customer is only paying the minimum amount due. Paying only the minimum can be a sign of financial distress.\n\n* amount_invested_monthly: Money the customer invests each month. Higher investment could indicate better financial management.\n\n* payment_behaviour: The customer's payment habits, potentially categorized (e.g., “pays on time,” “pays after due date”). Strongly indicative of creditworthiness.\n\n* monthly_balance: The remaining balance after all monthly payments. Higher balances can indicate healthy cash flow and financial stability.\n\n* credit_score: This is likely the target variable you’re trying to predict in the classification model. A credit score typically categorizes customers based on their credit risk level.","metadata":{}},{"cell_type":"markdown","source":"To understand the relationships among our features and their correlation with the target variable, we start by selecting only the numeric columns from the dataset for correlation analysis. Using these numeric features, we calculate the correlation matrix, which shows how each feature correlates with the others. We then visualize this matrix using a heatmap to quickly identify highly correlated pairs, where positive correlations are shown in warm colors and negative correlations in cool colors.\n\nNext, we assess each feature's direct correlation with the target variable, credit_score, to highlight which features most strongly influence our predictions. By sorting these correlations, we gain insights into which features could be particularly valuable for our model, helping guide feature selection and further exploration.\n\n\n\n## Step 6: Exploring Feature Correlations and Identifying Key Predictors\n\nIn this step, we analyze the relationships between our numeric features and identify which features are most strongly correlated with our target variable, credit_score. This will help us better understand the dataset and potentially guide feature selection for modeling.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Select only numeric columns\nnumeric_df = df.select_dtypes(include='number')\n\n# Calculate the correlation matrix for numeric data\ncorrelation_matrix = numeric_df.corr()\n\n# Plot the heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()\n\n# Get correlation of each feature with the target variable (assumed to be 'credit_score')\n# Make sure 'credit_score' is in numeric_df\nif 'credit_score' in correlation_matrix.columns:\n    target_corr = correlation_matrix['credit_score'].sort_values(ascending=False)\n\n    # Display the top features correlated with the target\n    print(\"Top features correlated with credit_score:\")\n    print(target_corr[1:])  # Excluding 'credit_score' itself\nelse:\n    print(\"The target variable 'credit_score' is not in numeric columns. Please ensure it is numeric.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T18:20:50.874037Z","iopub.execute_input":"2024-10-29T18:20:50.875186Z","iopub.status.idle":"2024-10-29T18:20:52.243216Z","shell.execute_reply.started":"2024-10-29T18:20:50.875141Z","shell.execute_reply":"2024-10-29T18:20:52.242165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 7: Selecting Key Features for Model Training and Splitting Data\n\nTo streamline the user experience and ensure this model is practical for deployment, I selected a subset of features that are most correlated with the target variable, credit_score. By focusing on a limited set of features—specifically interest_rate, num_credit_inquiries, delay_from_due_date, num_credit_card, num_bank_accounts, outstanding_debt, num_of_delayed_payment, and num_of_loan—we can reduce user input fatigue while still capturing the information necessary for accurate predictions. This approach optimizes for ease of use without sacrificing prediction quality.\n\nIn this code, I:\n\n* **Selected the Key Features**: I defined X as the DataFrame containing only the most relevant columns, as identified in the correlation analysis.\n* **Set the Target Variable**: Defined y as the target variable credit_score.\n* **Split the Data**: Divided the dataset into training and testing sets with a 75-25 ratio, reserving 25% of the data for model evaluation. The random_state is set to 42 for reproducibility.\n\nThis setup ensures a clear structure for training and evaluation, preparing the data for the next stage: training the XGBClassifier model and assessing its performance.\n\n\n\n## Step 8: Model Training and Evaluation\n\nIn this step, I initialized the XGBClassifier model, setting use_label_encoder to False and specifying logloss as the evaluation metric. I then fit the model using the training dataset X_train and y_train. Following the training, I made predictions on the test dataset X_test, which resulted in a predicted class array y_pred.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport joblib\n\n# Selecting features and target\nX = df[['interest_rate', 'num_credit_inquiries', 'delay_from_due_date', \n        'num_credit_card', 'num_bank_accounts', 'outstanding_debt', \n        'num_of_delayed_payment', 'num_of_loan']]\ny = df['credit_score']\n\n\n# Split data into 75% train and 25% test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:49:32.882563Z","iopub.execute_input":"2024-10-27T16:49:32.883297Z","iopub.status.idle":"2024-10-27T16:49:33.356132Z","shell.execute_reply.started":"2024-10-27T16:49:32.883249Z","shell.execute_reply":"2024-10-27T16:49:33.354819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n\n# Fit the model on training data\nxgb_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:49:53.33332Z","iopub.execute_input":"2024-10-27T16:49:53.333783Z","iopub.status.idle":"2024-10-27T16:49:54.832602Z","shell.execute_reply.started":"2024-10-27T16:49:53.333737Z","shell.execute_reply":"2024-10-27T16:49:54.83147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ny_pred = xgb_model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Model Accuracy:\", accuracy)\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:50:09.071673Z","iopub.execute_input":"2024-10-27T16:50:09.072179Z","iopub.status.idle":"2024-10-27T16:50:09.219288Z","shell.execute_reply.started":"2024-10-27T16:50:09.072135Z","shell.execute_reply":"2024-10-27T16:50:09.217567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model's performance was evaluated using the accuracy score and a classification report, which provided insight into precision, recall, and F1-scores for each credit score category:\n\n* **Model Accuracy**: 0.73236, indicating that the model correctly predicted the credit score category approximately 73% of the time.\n* **Classification Report**: This report shows precision, recall, and F1-scores for each category (0, 1, and 2), with precision and recall values suggesting a balanced performance across different credit score categories. The model performed slightly better on the \"Standard\" category (1) and showed room for improvement on the \"Poor\" category (2).\n\nGiven these results, there is an opportunity to enhance the model's performance further. Therefore, I plan to implement GridSearchCV to optimize hyperparameters, which should help increase the model's accuracy and overall predictive capabilities.","metadata":{}},{"cell_type":"markdown","source":"## Step 9: Hyperparameter Tuning with GridSearchCV\n\nIn this step, I employed **GridSearchCV** to optimize the hyperparameters of the XGBClassifier model. A parameter grid was defined, encompassing various options for n_estimators, learning_rate, max_depth, subsample, and colsample_bytree. This exhaustive search allowed for the exploration of a total of 243 different combinations of these parameters across 3 cross-validation folds.\n\nUpon fitting the grid search to the training data, the model identified the best parameters that yielded the highest cross-validation accuracy. The results indicated:\n\n**Best Parameters**:\n* colsample_bytree: 1.0\n* learning_rate: 0.1\n* max_depth: 7\n* n_estimators: 300\n* subsample: 0.8\n\n**Best Cross-Validation Accuracy**: 0.7525, demonstrating an improvement over the previous model.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'max_depth': [3, 5, 7],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0]\n}\n\n# Initialize XGBClassifier\nxgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Cross-Validation Accuracy:\", best_score)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:53:09.187142Z","iopub.execute_input":"2024-10-27T16:53:09.18834Z","iopub.status.idle":"2024-10-27T17:16:54.755492Z","shell.execute_reply.started":"2024-10-27T16:53:09.188288Z","shell.execute_reply":"2024-10-27T17:16:54.754199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the optimal hyperparameters determined, I initialized a new instance of XGBClassifier using these best parameters and fit the model on the training data.\n\nNext, I evaluated the optimized model on the test set, which resulted in:\n\n* **Optimized Model Accuracy**: 0.76, indicating that the model correctly predicted credit scores approximately 76% of the time.\n* **Classification Report**: The report showcased improved precision, recall, and F1-scores across all categories, with the \"Standard\" category (1) performing particularly well.\n\nOverall, the hyperparameter tuning significantly enhanced the model's performance, laying a solid foundation for future deployment and practical use.","metadata":{}},{"cell_type":"code","source":"# Initialize XGBClassifier with the best parameters\noptimized_xgb = XGBClassifier(\n    n_estimators=best_params['n_estimators'],\n    learning_rate=best_params['learning_rate'],\n    max_depth=best_params['max_depth'],\n    subsample=best_params['subsample'],\n    colsample_bytree=best_params['colsample_bytree'],\n    use_label_encoder=False,\n    eval_metric=\"logloss\"\n)\n\n# Fit the model on training data\noptimized_xgb.fit(X_train, y_train)\n\n# Evaluate on the test set\ny_pred_optimized = optimized_xgb.predict(X_test)\n\n# Calculate accuracy and other metrics\noptimized_accuracy = accuracy_score(y_test, y_pred_optimized)\nprint(\"Optimized Model Accuracy:\", optimized_accuracy)\nprint(classification_report(y_test, y_pred_optimized))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:16:54.757539Z","iopub.execute_input":"2024-10-27T17:16:54.758687Z","iopub.status.idle":"2024-10-27T17:17:00.565783Z","shell.execute_reply.started":"2024-10-27T17:16:54.758639Z","shell.execute_reply":"2024-10-27T17:17:00.564235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 10: Displaying Best Parameters and Saving the Model\n\nIn this step, I displayed the best parameters identified during the GridSearchCV process along with the corresponding best estimator. The output provides insight into the optimal settings that led to improved model performance:\n\n* **Best Parameters**: This output shows the specific values for colsample_bytree, learning_rate, max_depth, n_estimators, and subsample that were found to yield the highest accuracy during the hyperparameter tuning process.\n\n* **Best Estimator**: This displays the full model configuration, encapsulating the chosen hyperparameters. This provides a clear reference point for replicating the model in the future or for further analysis.","metadata":{}},{"cell_type":"code","source":"# Display the best parameters and the full estimator with those parameters\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(\"Best Estimator:\", grid_search.best_estimator_)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:31:58.53169Z","iopub.execute_input":"2024-10-27T17:31:58.532219Z","iopub.status.idle":"2024-10-27T17:31:58.54064Z","shell.execute_reply.started":"2024-10-27T17:31:58.532173Z","shell.execute_reply":"2024-10-27T17:31:58.539283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following the evaluation of the optimized model, I proceeded to save the final XGBClassifier model using the `joblib` library. This step ensures that the model can be easily loaded and deployed later for real-world applications without needing to retrain. The model is saved as xgb_credit_score_model.pkl, providing a convenient and efficient means to utilize the trained model for predicting credit scores in practical scenarios.","metadata":{}},{"cell_type":"code","source":"# Save the model\njoblib.dump(xgb_model, 'xgb_credit_score_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:47:04.767503Z","iopub.execute_input":"2024-10-27T18:47:04.768069Z","iopub.status.idle":"2024-10-27T18:47:04.794065Z","shell.execute_reply.started":"2024-10-27T18:47:04.767997Z","shell.execute_reply":"2024-10-27T18:47:04.792984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Credit Score Prediction Model Deployment\n\nThis Notebook demonstrates the code I used to deploy a credit score prediction model using Gradio. My Gradio app is already live, and you can access it here: [Gradio Credit Score Predictor](https://huggingface.co/spaces/nukimayasari/creditscore).\n\nSince Kaggle doesn’t support long-term hosting, this Notebook is provided as a guide for anyone interested in learning about deploying machine learning models. By following these steps, you’ll get an understanding of how to set up a Gradio app to run locally (or in a cloud environment) and gain insights into the deployment process.\n\n**Note**: This code is not actively deployed from this Notebook. Instead, it shows the process I used to deploy on Gradio's Hugging Face Spaces, where you can interact with the live model.\n\n---\n\n## Step-by-Step Instructions\n\n### Step 1: Import Libraries\n\nTo start, we need to import the necessary libraries. Here, `gradio` is used to create the web interface, `pickle` for loading the saved model, `numpy` for handling input data, and `warnings` to manage any model warnings.\n\n```python\nimport gradio as gr\nimport pickle\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning, message=\"If you are loading a serialized model\")\n","metadata":{}},{"cell_type":"markdown","source":"### Suppress Warnings\nWe'll suppress warnings related to model loading for a cleaner output.","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"If you are loading a serialized model\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Load the Saved Model\nIn this step, we load the pre-trained model using pickle. Make sure your model file (xgb_credit_score_model.pkl) is in the same directory as this Notebook if you're running it locally","metadata":{}},{"cell_type":"code","source":"# Load your saved model\nwith open('xgb_credit_score_model.pkl', 'rb') as file:\n    model = pickle.load(file)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Define the Prediction Function\nHere, we define a function predict_credit_score() that takes in the user inputs (interest rate, number of credit inquiries, delay from the due date, etc.) and arranges them into a format that the model expects. The function outputs the predicted credit score category.","metadata":{}},{"cell_type":"code","source":"# Define the prediction function\ndef predict_credit_score(interest_rate, num_credit_inquiries, delay_from_due_date, \n                         num_credit_card, num_bank_accounts, outstanding_debt, \n                         num_of_delayed_payment, num_of_loan):\n    # Arrange inputs into a format that the model expects\n    features = np.array([[interest_rate, num_credit_inquiries, delay_from_due_date, \n                          num_credit_card, num_bank_accounts, outstanding_debt, \n                          num_of_delayed_payment, num_of_loan]])\n    prediction = model.predict(features)\n    return f\"Predicted Credit Score Category: {int(prediction[0])}\"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Set Up the Gradio Interface\nWe set up the input and output interfaces with gradio.Interface. This includes labeling each input field (e.g., \"Interest Rate\") to make the app user-friendly and adding a description for the credit score categories (2: Good, 1: Standard, 0: Poor).","metadata":{}},{"cell_type":"code","source":"# Define the Gradio input interface with labeled inputs\ninputs = [\n    gr.Number(label=\"Interest Rate\"),\n    gr.Number(label=\"Number of Credit Inquiries\"),\n    gr.Number(label=\"Days Delayed from Due Date\"),\n    gr.Number(label=\"Number of Credit Cards\"),\n    gr.Number(label=\"Number of Bank Accounts\"),\n    gr.Number(label=\"Outstanding Debt\"),\n    gr.Number(label=\"Number of Delayed Payments\"),\n    gr.Number(label=\"Number of Loans\")\n]\n\n# Define a detailed description with the correct category explanation\ndescription = \"\"\"\nEnter your details to get a prediction of your credit score category.\n\n**Credit Score Categories**:\n- 2 = Good\n- 1 = Standard\n- 0 = Poor\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 5: Launch the Gradio Interface\nThe final step involves launching the Gradio app interface, where the function and input setup are used to define the full application. If running locally, you can set share=True to generate a shareable link.","metadata":{}},{"cell_type":"code","source":"# Define the Gradio interface\ngr.Interface(fn=predict_credit_score, inputs=inputs, outputs=\"text\",\n             title=\"Credit Score Predictor\",\n             description=description).launch()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\nIn this notebook, we successfully developed a predictive model for assessing credit scores using a well-structured dataset. The key takeaways from this process include:\n\n* **Data Understanding and Preparation**: We began by exploring the dataset, examining the features, and identifying those with the highest correlations to the target variable, credit score. This step was crucial in selecting the most relevant features to minimize user input fatigue during deployment.\n\n* **Model Selection and Training**: We utilized the XGBoost classifier, a robust algorithm known for its performance in classification tasks. By fitting the model to our training data, we established a baseline accuracy of approximately 73.2%.\n\n* **Hyperparameter Optimization**: To enhance model performance, we employed GridSearchCV to identify the optimal hyperparameters, leading to an improved accuracy of 75.25%. This fine-tuning is essential for maximizing the model's predictive capabilities.\n\n* **Evaluation and Results**: After optimizing our model, we evaluated it on a separate test set, achieving a final accuracy of 76%. The classification report highlighted the model's precision, recall, and F1-score for each class, demonstrating its effectiveness in predicting credit scores.\n\n* **Deployment Readiness**: By saving the trained model as a .pkl file, we prepared it for deployment, ensuring that it can be easily integrated into applications for real-time credit score predictions. This step is vital as it allows end users to leverage the model's insights without needing extensive data science expertise.\n\n* **Deployment Process**: The deployment process involves wrapping the saved model within a user-friendly interface, such as a web application using frameworks like Gradio or Flask. This enables users to input their financial details easily and receive instant credit score predictions. Additionally, regular monitoring and updating of the model are essential to maintain its accuracy over time, especially as new data becomes available.\n\nOverall, this notebook illustrates the entire workflow of building a predictive model, from data exploration to deployment readiness. The methodologies and techniques applied here can serve as a guide for future projects in credit scoring or similar predictive tasks, emphasizing the importance of making data-driven insights accessible to end users.","metadata":{}}]}